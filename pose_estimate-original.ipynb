{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003a2310-a2ec-4dff-86c0-15e44f28eda1",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"pose_landmarks_index.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8205430f-3b99-4b58-8d11-9483134454fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connections_of_interest = [\n",
    "    (0, 2),   # nose, left eye\n",
    "    (0, 5),   # nose, right eye\n",
    "    (0, 7),   # nose, left ear\n",
    "    (0, 8),   # nose, right ear\n",
    "    (0, 9),   # nose, left mouth\n",
    "    (0, 10),  # nose, right mouth\n",
    "    (2, 5),   # left eye, right eye\n",
    "    (2, 7),   # left eye, left ear\n",
    "    (5, 8),   # right eye, right ear\n",
    "    (7, 9),   # left ear, left mouth\n",
    "    (7, 11),  # Left ear, left shoulder\n",
    "    (8, 10),  # right ear, right mouth\n",
    "    (8, 12),  # right ear, right shoulder\n",
    "    (9, 10),  # left mouth, right mouth\n",
    "    (9, 11),  # left mouth, left shoulder\n",
    "    (10, 12), # right mout, right shoulder\n",
    "    (11, 12), # left shoulder, right shoulder\n",
    "    (12,10),  # Right shoulder, right mouth\n",
    "]\n",
    "\n",
    "connections_descriptions = {\n",
    "    (0, 2): \"nose, left eye\",\n",
    "    (0, 5): \"nose, right eye\",\n",
    "    (0, 7): \"nose, left ear\",\n",
    "    (0, 8): \"nose, right ear\",\n",
    "    (0, 9): \"nose, left mouth\",\n",
    "    (0, 10): \"nose, right mouth\",\n",
    "    (2, 5): \"left eye, right eye\",\n",
    "    (2, 7): \"left eye, left ear\",\n",
    "    (5, 8): \"right eye, right ear\",\n",
    "    (7, 9): \"left ear, left mouth\",\n",
    "    (7, 11): \"Left ear, left shoulder\",\n",
    "    (8, 10): \"right ear, right mouth\",\n",
    "    (8, 12): \"right ear, right shoulder\",\n",
    "    (9, 10): \"left mouth, right mouth\",\n",
    "    (9, 11): \"left mouth, left shoulder\",\n",
    "    (10, 12): \"right mout, right shoulder\",\n",
    "    (11, 12): \"left shoulder, right shoulder\",\n",
    "    (12, 10): \"right shoulder, right mouth\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d45382-3d2c-475e-92eb-deee3596a1c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import random\n",
    "import math\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f9f63f9-21a0-444f-bcc6-cd23f0d0a8cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_data = Path(r\"./ml_assignment_data\")\n",
    "\n",
    "#actions that we try to detect\n",
    "actions = ['C','TL','TR','BL','BR']\n",
    "actions_description = {'C':'MIDDEN','TL':'LINKS BOVEN','TR':'RECHTS BOVEN','BL':'LINKS ONDER','BR':'RECHTS ONDER' }\n",
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38b629ea-d37d-4880-8234-b7755873cfb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(np_file):\n",
    "    # read a flattened file and reshape and return only x and y\n",
    "    flat_file = np.load(np_file)\n",
    "    num_landmarks = len(flat_file) // 4\n",
    "    return flat_file.reshape(num_landmarks, 4)\n",
    "\n",
    "file= Path(r\"C:\\Users\\djase\\Documents\\Projecten\\ML\\ml_assignment_data\\person_0000\\BL\\0\\0.npy\")\n",
    "assert(read_file(str(file)).shape == (33,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b313e305-7593-48fa-84a0-1a0463673c33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "def calculate_distance(results):\n",
    "    distances =[]\n",
    "    for connection in connections_of_interest:\n",
    "        \n",
    "        sx, sy, _, _ = tuple(results[connection[0]])\n",
    "        ex, ey, _, _ = tuple(results[connection[1]])\n",
    "        distances.append( math.sqrt(math.pow(sx-ex,2) + math.pow(sy - ey,2)))\n",
    "\n",
    "    return distances\n",
    "        \n",
    "file= Path(r\"C:\\Users\\djase\\Documents\\Projecten\\ML\\ml_assignment_data\\person_0000\\BL\\0\\0.npy\")\n",
    "data = read_file(str(file))\n",
    "dist = calculate_distance(data)\n",
    "assert (len(dist)==len(connections_descriptions)==len(connections_of_interest))\n",
    "print(len(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2984140e-f295-4a76-8a9d-fd107dfa3e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 7500 , and labels 7500\n"
     ]
    }
   ],
   "source": [
    "def read_data(actions: List)-> Dict:\n",
    "    person_folders = [x for x in project_data.iterdir() if x.is_dir() and str(x.name).split('_')[-2] == 'person']\n",
    "    samples= [] \n",
    "    labels =[]\n",
    "    pers_id=[]\n",
    "    global series\n",
    "    global frames\n",
    "    p_id = 0\n",
    "    for person_folder in person_folders:\n",
    "        for action in actions:\n",
    "            action_folder = person_folder / action\n",
    "            series = [x for x in action_folder.iterdir() if x.is_dir()]\n",
    "            for serie in series:\n",
    "                frames = [x for x in serie.iterdir() if x.is_file()]\n",
    "                frames = sorted(frames, key=lambda x: int(x.stem))\n",
    "                for frame in frames[-15:]: # take only the last 15 frames\n",
    "                    data = read_file(frame)\n",
    "                    dist = calculate_distance(data)\n",
    "                    samples.append(dist)\n",
    "                    labels.append(label_map[action])\n",
    "                    pers_id.append(p_id)\n",
    "        p_id += 1\n",
    "    return pers_id, samples, labels, \n",
    "\n",
    "actions = ['C','TL','TR','BL','BR']\n",
    "idx, sam, lbl,  = read_data(actions)\n",
    "print(f\"Number of samples: {len(sam)} , and labels {len(lbl)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58d5ea3b-bd73-4653-9c7c-b83a99567d69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([   (0, 2),    (0, 5),    (0, 7),    (0, 8),    (0, 9),   (0, 10),\n",
       "          (2, 5),    (2, 7),    (5, 8),    (7, 9),   (7, 11),   (8, 10),\n",
       "         (8, 12),   (9, 10),   (9, 11),  (10, 12),  (11, 12),  (12, 10),\n",
       "       'pers_id',   'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(sam, columns = connections_of_interest)\n",
    "df['pers_id']=idx\n",
    "df['class'] =  lbl\n",
    "df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b50c13c-8c8d-4620-ac18-8d182849d473",
   "metadata": {},
   "source": [
    "# Training KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46eace40-9466-4ffd-b675-34f00f4e5d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.svm as svm\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dc5dfb8-3732-49f9-9103-716f60e60a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y =read_data(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b962d4-b36a-40cb-9c53-0ecdbc2f169f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 4750 , and labels 4750\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples: {len(X)} , and labels {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6211e69c-1760-493c-b3a7-ecddbc4caa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 100.0  # SVM regularization parameter\n",
    "models = (\n",
    "    svm.SVC(kernel=\"linear\", C=C),\n",
    "    svm.LinearSVC(C=C, max_iter=10000, dual=\"auto\"),\n",
    "    svm.SVC(kernel=\"rbf\", gamma=0.7, C=C),\n",
    "    svm.SVC(kernel=\"poly\", degree=3, gamma=\"auto\", C=C),\n",
    ")\n",
    "models_fit = [clf.fit(X, y) for clf in models]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "917798bd-e03c-4495-a180-eac029900a11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100.0, kernel='linear')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models_fit:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining set score: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model\u001b[38;5;241m.\u001b[39mscore(X_train, y_train)))\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest set score: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)))\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "for model in models_fit:\n",
    "    print(model)\n",
    "    print(\"Training set score: {:.2f}\".format(model.score(X_train, y_train)))\n",
    "    print(\"Test set score: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f2e27-0257-432c-9eaf-b7b121e22b4d",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29742317-517e-4749-a5eb-fb7c3ef9a09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models_fit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a3e6a2-2cf1-4be9-ac4b-6b2a8951562a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [3]\n"
     ]
    }
   ],
   "source": [
    "file= Path(r\"C:\\Users\\djase\\Documents\\Projecten\\ML\\ml_assignment_data\\person_0000\\BL\\3\\30.npy\")\n",
    "new_data = read_file(str(file))\n",
    "new_sample= calculate_distance(new_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict([new_sample])\n",
    "\n",
    "print(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d602df90-e507-4103-ada1-de05f6cad216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "351c6126-1322-4b39-b490-d9c3f8ccef75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable =False\n",
    "    results =  model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d78be43c-461f-43a3-82ef-4a6d2051204b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_custom_landmarks(image, results):\n",
    "    if results.pose_landmarks:\n",
    "    # Draw custom edges\n",
    "        for connection in connections_of_interest:\n",
    "            start_point = results.pose_landmarks.landmark[connection[0]]\n",
    "            end_point = results.pose_landmarks.landmark[connection[1]]\n",
    "\n",
    "            cv2.line(image, \n",
    "                     (int(start_point.x * image.shape[1]), int(start_point.y * image.shape[0])),\n",
    "                     (int(end_point.x * image.shape[1]), int(end_point.y * image.shape[0])),\n",
    "                     (255, 0, 0), 2) # Blue color, thickness 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8e98a12-344e-4689-89be-c8049f461a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_area(clf, results):\n",
    "    pose =[[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark] if results.pose_landmarks else np.zeros(33*4)\n",
    "    data = calculate_distance(pose)\n",
    "    return clf.predict([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e7ba187-ad79-481f-9044-7c6862b4a865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m draw_custom_landmarks(image, results)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results:\n\u001b[1;32m---> 15\u001b[0m     label \u001b[38;5;241m=\u001b[39m predict_area(model, results)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label:\n\u001b[0;32m     17\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mputText(image, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKIJKT NAAR \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactions_description[actions[label[\u001b[38;5;241m0\u001b[39m]]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m120\u001b[39m, \u001b[38;5;241m200\u001b[39m),\n\u001b[0;32m     18\u001b[0m                         cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m4\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mLINE_AA)\n",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m, in \u001b[0;36mpredict_area\u001b[1;34m(clf, results)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_area\u001b[39m(clf, results):\n\u001b[0;32m      2\u001b[0m     pose \u001b[38;5;241m=\u001b[39m[[res\u001b[38;5;241m.\u001b[39mx, res\u001b[38;5;241m.\u001b[39my, res\u001b[38;5;241m.\u001b[39mz, res\u001b[38;5;241m.\u001b[39mvisibility] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark] \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m33\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m calculate_distance(pose)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clf\u001b[38;5;241m.\u001b[39mpredict([data])\n",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m, in \u001b[0;36mcalculate_distance\u001b[1;34m(results)\u001b[0m\n\u001b[0;32m      2\u001b[0m distances \u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m connection \u001b[38;5;129;01min\u001b[39;00m connections_of_interest:\n\u001b[1;32m----> 5\u001b[0m     sx, sy, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(results[connection[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m      6\u001b[0m     ex, ey, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(results[connection[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m      7\u001b[0m     distances\u001b[38;5;241m.\u001b[39mappend( math\u001b[38;5;241m.\u001b[39msqrt(math\u001b[38;5;241m.\u001b[39mpow(sx\u001b[38;5;241m-\u001b[39mex,\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39mpow(sy \u001b[38;5;241m-\u001b[39m ey,\u001b[38;5;241m2\u001b[39m)))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "# webcam is max 1920 x 1080\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW) \n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920/2)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080/2)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        #draw_styled_landmarks(image, results)\n",
    "        draw_custom_landmarks(image, results)\n",
    "        if results:\n",
    "            label = predict_area(model, results)\n",
    "            if label:\n",
    "                cv2.putText(image, f'KIJKT NAAR {actions_description[actions[label[0]]]}', (120, 200),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"Camera feed:\", image)\n",
    "        if cv2.waitKey(10) & 0xff == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7614f678-3631-42df-956f-7fd0c666d676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7288db-b399-43d5-8e94-4a83c55d64c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
